{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Found\n",
      "Folder Found\n",
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against']\n"
     ]
    }
   ],
   "source": [
    "#program to check whether a particular file exist or not\n",
    "import os\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "\n",
    "file_name = \"text8.zip\"\n",
    "if(os.path.exists(file_name)):\n",
    "    print(\"File Found\")\n",
    "else:\n",
    "    url = 'http://mattmahoney.net/dc/'\n",
    "    file_name = urlretrieve(url+file_name,file_name)\n",
    "    print(\"File Downloaded Successfully\")\n",
    "\n",
    "#Extracting the zip file in separate folder\n",
    "folder = \"Corpus\"\n",
    "import zipfile\n",
    "#check if directory already exists\n",
    "if not os.path.isdir(folder):\n",
    "    print(\"Folder Not Found\")\n",
    "    with zipfile.ZipFile(file_name) as zf:\n",
    "        zf.extractall(folder)\n",
    "else:\n",
    "    print(\"Folder Found\")\n",
    "\n",
    "    \n",
    "# reading the extracted text file\n",
    "with open('Corpus/text8') as tf:\n",
    "    full_text = tf.read()\n",
    "#print(full_text.split()[0])\n",
    "\n",
    "#CREATING A FUNCTION THAT GIVES NAMES TO THE PUNCTUATIONS\n",
    "def punc_tokenize(full_text):\n",
    "    full_text = full_text.lower();\n",
    "    full_text = full_text.replace('.',' <full_stop> ')\n",
    "    full_text = full_text.replace(',',' <comma> ')\n",
    "    full_text = full_text.replace('\"',' <quotes> ')\n",
    "    full_text = full_text.replace(';',' <semi_colon> ')\n",
    "    full_text = full_text.replace('!',' <exclamation> ')\n",
    "    full_text = full_text.replace('?',' <question> ')\n",
    "    full_text = full_text.replace('(',' <open_paranth> ')\n",
    "    full_text = full_text.replace('-',' <hyphen> ')\n",
    "    full_text = full_text.replace(';',' <colon> ')\n",
    "    return full_text.split()\n",
    "\n",
    "tokenized_text = punc_tokenize(full_text)\n",
    "print(tokenized_text[:10])    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including']\n"
     ]
    }
   ],
   "source": [
    "import collections as cl\n",
    "count = cl.Counter(tokenized_text)\n",
    "new_text = [w for w in tokenized_text if count[w] > 7]\n",
    "print(new_text[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Workds:53721 and Total Number of Words:16616688\n"
     ]
    }
   ],
   "source": [
    "#checking lenght of tokenized text\n",
    "unique = len(set(new_text))\n",
    "total = len(new_text)\n",
    "print(\"Total Unique Workds:%d and Total Number of Words:%d\"%(unique,total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'the'), (1, 'of'), (2, 'and'), (3, 'one'), (4, 'in'), (5, 'a'), (6, 'to'), (7, 'zero'), (8, 'nine'), (9, 'two')]\n",
      "0\n",
      "anarchism\n"
     ]
    }
   ],
   "source": [
    "#All the text are labeled with integers in a way that word with maximum frequency get 0\n",
    "def Conv_To_Integer(text):\n",
    "    count = cl.Counter(text)\n",
    "    \n",
    "def func(x): \n",
    "    return x[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "# random list\n",
    "random = [(2, 2), (3, 4), (4, 1), (1, 3)]\n",
    "# sort list with key\n",
    "sorted_list = sorted(random, key = func)\n",
    "'''\n",
    "\n",
    "#Enumerate is used to give the index to the elements in a list\n",
    "def dict_Creation(new_text):\n",
    "    count = cl.Counter(new_text)\n",
    "    sorted_words = sorted(count, key =count.get, reverse = True)\n",
    "    index = {ii:word for ii,word in enumerate(sorted_words)}\n",
    "    reverse_index = {word:ii for ii,word in index.items()}\n",
    "    return index,reverse_index\n",
    "\n",
    "index,reverse_index = dict_Creation(new_text)\n",
    "print(list(index.items())[0:10])\n",
    "print(reverse_index[\"the\"])\n",
    "#print(count['the'])\n",
    "total = len(count)\n",
    "\n",
    "#finding the probability of each word in the text\n",
    "freq = {word:count/total for word,count in count.items() }\n",
    "\n",
    "t = 0.00005\n",
    "#finding the probability of the word, We are using this to remove the Stop words\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "p_drop ={word: 1 -np.sqrt(t/freq[word]) for word in count}\n",
    "train_words = [word for word in count if p_drop[word]<random.random()]\n",
    "\n",
    "print(train_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
